{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-hoc Repacking Analysis for H2O Molecule\n",
    "\n",
    "This notebook demonstrates three Pauli grouping strategies:\n",
    "1. **Baseline**: Sorted insertion grouping\n",
    "2. **Greedy Repacking**: Optimize grouping from scratch for minimum variance\n",
    "3. **Post-hoc Repacking**: Add paulis from previous groups if they're diagonal under existing circuits\n",
    "\n",
    "We compare these methods on both simulated and real IBM hardware data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import openfermion as of\n",
    "import cirq\n",
    "from collections import Counter\n",
    "\n",
    "from grouping import MeasurementGroups, sorted_insertion_grouping\n",
    "from repacking import greedy_repacking, posthoc_repacking\n",
    "from measurement import create_measurement_setups\n",
    "from estimation import estimate_from_groups\n",
    "from cache import GroupingCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load H2O Hamiltonian\n",
    "\n",
    "Load the water molecule Hamiltonian (14 qubits, 1620 Pauli terms) and compute exact HF energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamiltonian: 1620 Pauli terms on 14 qubits\n",
      "Exact HF energy: -75.679017 Ha\n"
     ]
    }
   ],
   "source": [
    "# Load molecular data\n",
    "mol_data = of.chem.MolecularData(filename='monomer_eqb.hdf5')\n",
    "n_electrons = mol_data.n_electrons\n",
    "\n",
    "# Convert to qubit Hamiltonian\n",
    "hamiltonian_fermion = of.jordan_wigner(\n",
    "    of.get_fermion_operator(mol_data.get_molecular_hamiltonian())\n",
    ")\n",
    "hamiltonian = of.qubit_operator_to_pauli_sum(hamiltonian_fermion)\n",
    "\n",
    "# Setup qubits\n",
    "qubits = cirq.LineQubit.range(14)\n",
    "\n",
    "# Compute exact HF energy\n",
    "hf_energy_exact = 0.0\n",
    "for pauli_string in hamiltonian:\n",
    "    coeff = pauli_string.coefficient\n",
    "    exp_value = 1.0\n",
    "    for qubit in qubits:\n",
    "        if qubit in pauli_string.qubits:\n",
    "            gate = pauli_string[qubit]\n",
    "            qubit_idx = qubit.x\n",
    "            if qubit_idx < n_electrons:\n",
    "                if gate == cirq.Z:\n",
    "                    exp_value *= -1\n",
    "                elif gate in [cirq.X, cirq.Y]:\n",
    "                    exp_value = 0.0\n",
    "                    break\n",
    "            else:\n",
    "                if gate in [cirq.X, cirq.Y]:\n",
    "                    exp_value = 0.0\n",
    "                    break\n",
    "    hf_energy_exact += np.real(coeff * exp_value)\n",
    "\n",
    "print(f\"Hamiltonian: {len(hamiltonian)} Pauli terms on {len(qubits)} qubits\")\n",
    "print(f\"Exact HF energy: {hf_energy_exact:.6f} Ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Sorted Insertion Grouping\n",
    "\n",
    "Group Pauli terms using sorted insertion - the standard greedy algorithm that groups commuting terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Grouping Statistics:\n",
      "  Number of groups: 65\n",
      "  Total paulis: 1619\n",
      "  Average paulis per group: 24.9\n",
      "  Min paulis in a group: 2\n",
      "  Max paulis in a group: 105\n"
     ]
    }
   ],
   "source": [
    "# Perform sorted insertion grouping\n",
    "baseline_groups = sorted_insertion_grouping(hamiltonian)\n",
    "baseline_setups = create_measurement_setups(baseline_groups.groups, qubits)\n",
    "\n",
    "# Statistics\n",
    "num_groups_baseline = len(baseline_groups.groups)\n",
    "num_paulis_baseline = sum(len(g) for g in baseline_groups.groups)\n",
    "avg_paulis_per_group_baseline = num_paulis_baseline / num_groups_baseline\n",
    "\n",
    "print(f\"Baseline Grouping Statistics:\")\n",
    "print(f\"  Number of groups: {num_groups_baseline}\")\n",
    "print(f\"  Total paulis: {num_paulis_baseline}\")\n",
    "print(f\"  Average paulis per group: {avg_paulis_per_group_baseline:.1f}\")\n",
    "print(f\"  Min paulis in a group: {min(len(g) for g in baseline_groups.groups)}\")\n",
    "print(f\"  Max paulis in a group: {max(len(g) for g in baseline_groups.groups)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Repacking\n",
    "\n",
    "Repack strings to minimize expected variance.  This does a second greedy pass scoring strings according to c_i^2/N_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Repacking Statistics:\n",
      "  Number of groups: 65\n",
      "  Total paulis: 5057\n",
      "  Average paulis per group: 77.8\n",
      "  Min paulis in a group: 33\n",
      "  Max paulis in a group: 105\n",
      "\n",
      "Comparison to Baseline:\n",
      "  Paulis added: 3438 (212% increase)\n",
      "  Groups changed: 65 (same)\n"
     ]
    }
   ],
   "source": [
    "# Perform greedy repacking\n",
    "greedy_groups = greedy_repacking(baseline_groups, verbose=False)\n",
    "greedy_setups = create_measurement_setups(greedy_groups.groups, qubits)\n",
    "\n",
    "# Statistics\n",
    "num_groups_greedy = len(greedy_groups.groups)\n",
    "num_paulis_greedy = sum(len(g) for g in greedy_groups.groups)\n",
    "avg_paulis_per_group_greedy = num_paulis_greedy / num_groups_greedy\n",
    "\n",
    "print(f\"Greedy Repacking Statistics:\")\n",
    "print(f\"  Number of groups: {num_groups_greedy}\")\n",
    "print(f\"  Total paulis: {num_paulis_greedy}\")\n",
    "print(f\"  Average paulis per group: {avg_paulis_per_group_greedy:.1f}\")\n",
    "print(f\"  Min paulis in a group: {min(len(g) for g in greedy_groups.groups)}\")\n",
    "print(f\"  Max paulis in a group: {max(len(g) for g in greedy_groups.groups)}\")\n",
    "\n",
    "# Comparison to baseline\n",
    "paulis_added_greedy = num_paulis_greedy - num_paulis_baseline\n",
    "percent_increase_greedy = (paulis_added_greedy / num_paulis_baseline) * 100\n",
    "\n",
    "print(f\"\\nComparison to Baseline:\")\n",
    "print(f\"  Paulis added: {paulis_added_greedy} ({percent_increase_greedy:.0f}% increase)\")\n",
    "print(f\"  Groups changed: {num_groups_baseline} (same)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-hoc Repacking\n",
    "\n",
    "Add paulis from previous groups if they commute with current group AND are diagonal under the group's circuit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-hoc Repacking Statistics:\n",
      "  Number of groups: 65\n",
      "  Total paulis: 4825\n",
      "  Average paulis per group: 74.2\n",
      "  Min paulis in a group: 31\n",
      "  Max paulis in a group: 105\n",
      "\n",
      "Comparison to Baseline:\n",
      "  Paulis added: 3206 (198% increase)\n",
      "  Groups changed: 65 (same)\n",
      "\n",
      "Circuit Reuse:\n",
      "  Exact matches: 6\n",
      "  Conjugated: 2\n",
      "  Regenerated: 57\n",
      "  Total reused: 8/65 (12%)\n"
     ]
    }
   ],
   "source": [
    "# Perform post-hoc repacking\n",
    "posthoc_groups = posthoc_repacking(\n",
    "    baseline_groups,\n",
    "    baseline_setups,\n",
    "    qubits,\n",
    "    verbose=False\n",
    ")\n",
    "posthoc_setups = create_measurement_setups(posthoc_groups.groups, qubits)\n",
    "\n",
    "# Statistics\n",
    "num_groups_posthoc = len(posthoc_groups.groups)\n",
    "num_paulis_posthoc = sum(len(g) for g in posthoc_groups.groups)\n",
    "avg_paulis_per_group_posthoc = num_paulis_posthoc / num_groups_posthoc\n",
    "\n",
    "print(f\"Post-hoc Repacking Statistics:\")\n",
    "print(f\"  Number of groups: {num_groups_posthoc}\")\n",
    "print(f\"  Total paulis: {num_paulis_posthoc}\")\n",
    "print(f\"  Average paulis per group: {avg_paulis_per_group_posthoc:.1f}\")\n",
    "print(f\"  Min paulis in a group: {min(len(g) for g in posthoc_groups.groups)}\")\n",
    "print(f\"  Max paulis in a group: {max(len(g) for g in posthoc_groups.groups)}\")\n",
    "\n",
    "# Comparison to baseline\n",
    "paulis_added_posthoc = num_paulis_posthoc - num_paulis_baseline\n",
    "percent_increase_posthoc = (paulis_added_posthoc / num_paulis_baseline) * 100\n",
    "\n",
    "print(f\"\\nComparison to Baseline:\")\n",
    "print(f\"  Paulis added: {paulis_added_posthoc} ({percent_increase_posthoc:.0f}% increase)\")\n",
    "print(f\"  Groups changed: {num_groups_baseline} (same)\")\n",
    "\n",
    "# Circuit reuse analysis\n",
    "circuits_reused = 0\n",
    "circuits_conjugated = 0\n",
    "circuits_exact = 0\n",
    "circuits_regenerated = 0\n",
    "\n",
    "for i in range(len(baseline_setups)):\n",
    "    baseline_circuit = baseline_setups[i].basis_rotation\n",
    "    posthoc_circuit = posthoc_setups[i].basis_rotation\n",
    "    \n",
    "    if baseline_circuit == posthoc_circuit:\n",
    "        circuits_exact += 1\n",
    "        circuits_reused += 1\n",
    "    elif len(baseline_circuit) == len(posthoc_circuit):\n",
    "        # Check if they're the same up to qubit ordering\n",
    "        circuits_conjugated += 1\n",
    "        circuits_reused += 1\n",
    "    else:\n",
    "        circuits_regenerated += 1\n",
    "\n",
    "print(f\"\\nCircuit Reuse:\")\n",
    "print(f\"  Exact matches: {circuits_exact}\")\n",
    "print(f\"  Conjugated: {circuits_conjugated}\")\n",
    "print(f\"  Regenerated: {circuits_regenerated}\")\n",
    "print(f\"  Total reused: {circuits_reused}/{len(baseline_setups)} ({circuits_reused/len(baseline_setups)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Results\n",
    "\n",
    "Run simulations with the Hartree-Fock state to compare variance reduction across all three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulations with 100,000 shots per group...\n",
      "\n",
      "Simulating baseline...\n",
      "Simulating greedy repacking...\n",
      "Simulating post-hoc repacking...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create HF state\n",
    "hf_state = [1] * n_electrons + [0] * (len(qubits) - n_electrons)\n",
    "shots_per_group = 100000\n",
    "\n",
    "print(f\"Running simulations with {shots_per_group:,} shots per group...\\n\")\n",
    "\n",
    "# Generate measurement counts for each method\n",
    "def simulate_measurements(groups, setups, state, shots):\n",
    "    \"\"\"Simulate measurements for all groups.\"\"\"\n",
    "    all_counts = []\n",
    "    for group_idx, (group, setup) in enumerate(zip(groups.groups, setups)):\n",
    "        circuit = setup.basis_rotation\n",
    "        \n",
    "        # Apply circuit to state and get probabilities\n",
    "        simulator = cirq.Simulator()\n",
    "        initial_state_cirq = cirq.Circuit([cirq.X(qubits[i]) for i, bit in enumerate(state) if bit == 1])\n",
    "        full_circuit = initial_state_cirq + circuit\n",
    "        result = simulator.simulate(full_circuit)\n",
    "        \n",
    "        # Sample from the final state\n",
    "        sampler = cirq.Simulator()\n",
    "        samples = sampler.run(full_circuit + cirq.measure(*qubits), repetitions=shots)\n",
    "        \n",
    "        # Convert to counts dictionary\n",
    "        counts = Counter()\n",
    "        for measurement in samples.measurements.values():\n",
    "            for bitstring in measurement:\n",
    "                key = ''.join(str(int(b)) for b in bitstring)\n",
    "                counts[key] += 1\n",
    "        \n",
    "        all_counts.append(counts)\n",
    "    \n",
    "    return all_counts\n",
    "\n",
    "# Simulate all three methods\n",
    "print(\"Simulating baseline...\")\n",
    "baseline_counts = simulate_measurements(baseline_groups, baseline_setups, hf_state, shots_per_group)\n",
    "\n",
    "print(\"Simulating greedy repacking...\")\n",
    "greedy_counts = simulate_measurements(greedy_groups, greedy_setups, hf_state, shots_per_group)\n",
    "\n",
    "print(\"Simulating post-hoc repacking...\")\n",
    "posthoc_counts = simulate_measurements(posthoc_groups, posthoc_setups, hf_state, shots_per_group)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Simulation Results (HF State, 100k shots/group)\n",
      "================================================================================\n",
      "\n",
      "Exact HF energy: -75.679017 Ha\n",
      "\n",
      "Baseline:\n",
      "  Energy: -75.680290 ± 0.004028 Ha\n",
      "  Error: 0.001273 Ha\n",
      "  Variance: 1.622725e-05\n",
      "\n",
      "Greedy Repacking:\n",
      "  Energy: -75.679137 ± 0.001768 Ha\n",
      "  Error: 0.000120 Ha\n",
      "  Variance: 3.126856e-06\n",
      "  Variance reduction: 5.19x\n",
      "\n",
      "Post-hoc Repacking:\n",
      "  Energy: -75.680305 ± 0.001941 Ha\n",
      "  Error: 0.001288 Ha\n",
      "  Variance: 3.768386e-06\n",
      "  Variance reduction: 4.31x\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Estimate energies from simulated counts\n",
    "shots_list = [shots_per_group] * num_groups_baseline\n",
    "\n",
    "baseline_sim_results = estimate_from_groups(\n",
    "    baseline_groups,\n",
    "    baseline_setups,\n",
    "    baseline_counts,\n",
    "    shots_list,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "greedy_sim_results = estimate_from_groups(\n",
    "    greedy_groups,\n",
    "    greedy_setups,\n",
    "    greedy_counts,\n",
    "    shots_list,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "posthoc_sim_results = estimate_from_groups(\n",
    "    posthoc_groups,\n",
    "    posthoc_setups,\n",
    "    posthoc_counts,\n",
    "    shots_list,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*80)\n",
    "print(\"Simulation Results (HF State, 100k shots/group)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nExact HF energy: {hf_energy_exact:.6f} Ha\\n\")\n",
    "\n",
    "print(f\"Baseline:\")\n",
    "print(f\"  Energy: {baseline_sim_results.energy:.6f} ± {baseline_sim_results.energy_std():.6f} Ha\")\n",
    "print(f\"  Error: {abs(baseline_sim_results.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {baseline_sim_results.energy_variance:.6e}\")\n",
    "\n",
    "print(f\"\\nGreedy Repacking:\")\n",
    "print(f\"  Energy: {greedy_sim_results.energy:.6f} ± {greedy_sim_results.energy_std():.6f} Ha\")\n",
    "print(f\"  Error: {abs(greedy_sim_results.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {greedy_sim_results.energy_variance:.6e}\")\n",
    "print(f\"  Variance reduction: {baseline_sim_results.energy_variance / greedy_sim_results.energy_variance:.2f}x\")\n",
    "\n",
    "print(f\"\\nPost-hoc Repacking:\")\n",
    "print(f\"  Energy: {posthoc_sim_results.energy:.6f} ± {posthoc_sim_results.energy_std():.6f} Ha\")\n",
    "print(f\"  Error: {abs(posthoc_sim_results.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {posthoc_sim_results.energy_variance:.6e}\")\n",
    "print(f\"  Variance reduction: {baseline_sim_results.energy_variance / posthoc_sim_results.energy_variance:.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 2025 Hardware Data:\n",
      "  Groups: 65\n",
      "  Total shots: 3,250,000\n",
      "  Shots per group: 50,000\n",
      "\n",
      "================================================================================\n",
      "September 25 Hardware Results\n",
      "================================================================================\n",
      "\n",
      "Exact HF energy: -75.679017 Ha\n",
      "\n",
      "Baseline:\n",
      "  Energy: -73.551561 ± 0.006340 Ha\n",
      "  Error from exact: 2.127456 Ha\n",
      "  Variance: 4.019046e-05\n",
      "\n",
      "Post-hoc Repacking:\n",
      "  Energy: -67.995741 ± 0.011542 Ha\n",
      "  Error from exact: 7.683276 Ha\n",
      "  Variance: 1.332203e-04\n",
      "\n",
      "Variance reduction: 0.30x (-231.5% reduction)\n",
      "Std dev reduction: 0.55x\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load September 25 hardware data\n",
    "with open('all_counts_fez_sep25.pkl', 'rb') as f:\n",
    "    hardware_counts_sep = pickle.load(f)\n",
    "\n",
    "shots_per_group_hw = [sum(counts.values()) for counts in hardware_counts_sep]\n",
    "total_shots = sum(shots_per_group_hw)\n",
    "\n",
    "print(f\"September 2025 Hardware Data:\")\n",
    "print(f\"  Groups: {len(hardware_counts_sep)}\")\n",
    "print(f\"  Total shots: {total_shots:,}\")\n",
    "print(f\"  Shots per group: {shots_per_group_hw[0]:,}\\n\")\n",
    "\n",
    "# Analyze with baseline and post-hoc\n",
    "baseline_hw_sep = estimate_from_groups(\n",
    "    baseline_groups,\n",
    "    baseline_setups,\n",
    "    hardware_counts_sep,\n",
    "    shots_per_group_hw,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "posthoc_hw_sep = estimate_from_groups(\n",
    "    posthoc_groups,\n",
    "    posthoc_setups,\n",
    "    hardware_counts_sep,\n",
    "    shots_per_group_hw,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "variance_reduction_sep = baseline_hw_sep.energy_variance / posthoc_hw_sep.energy_variance\n",
    "std_reduction_sep = baseline_hw_sep.energy_std() / posthoc_hw_sep.energy_std()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"September 25 Hardware Results\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nExact HF energy: {hf_energy_exact:.6f} Ha\\n\")\n",
    "\n",
    "print(f\"Baseline:\")\n",
    "print(f\"  Energy: {baseline_hw_sep.energy:.6f} ± {baseline_hw_sep.energy_std():.6f} Ha\")\n",
    "print(f\"  Error from exact: {abs(baseline_hw_sep.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {baseline_hw_sep.energy_variance:.6e}\")\n",
    "\n",
    "print(f\"\\nPost-hoc Repacking:\")\n",
    "print(f\"  Energy: {posthoc_hw_sep.energy:.6f} ± {posthoc_hw_sep.energy_std():.6f} Ha\")\n",
    "print(f\"  Error from exact: {abs(posthoc_hw_sep.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {posthoc_hw_sep.energy_variance:.6e}\")\n",
    "\n",
    "print(f\"\\nVariance reduction: {variance_reduction_sep:.2f}x ({(1-1/variance_reduction_sep)*100:.1f}% reduction)\")\n",
    "print(f\"Std dev reduction: {std_reduction_sep:.2f}x\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 22 Hardware Data:\n",
      "  Groups: 65\n",
      "  Total shots: 3,250,000\n",
      "  Shots per group: 50,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load October 22 hardware data\n",
    "with open('all_counts_fez_oct22_3.pkl', 'rb') as f:\n",
    "    hardware_counts_oct = pickle.load(f)\n",
    "\n",
    "print(f\"October 22 Hardware Data:\")\n",
    "print(f\"  Groups: {len(hardware_counts_oct)}\")\n",
    "print(f\"  Total shots: {sum(sum(counts.values()) for counts in hardware_counts_oct):,}\")\n",
    "print(f\"  Shots per group: {sum(hardware_counts_oct[0].values()):,}\\n\")\n",
    "\n",
    "# Analyze with baseline and post-hoc\n",
    "baseline_hw_oct = estimate_from_groups(\n",
    "    baseline_groups,\n",
    "    baseline_setups,\n",
    "    hardware_counts_oct,\n",
    "    shots_per_group_hw,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "posthoc_hw_oct = estimate_from_groups(\n",
    "    posthoc_groups,\n",
    "    posthoc_setups,\n",
    "    hardware_counts_oct,\n",
    "    shots_per_group_hw,\n",
    "    qubits\n",
    ")\n",
    "\n",
    "variance_reduction_oct = baseline_hw_oct.energy_variance / posthoc_hw_oct.energy_variance\n",
    "std_reduction_oct = baseline_hw_oct.energy_std() / posthoc_hw_oct.energy_std()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"October 22 Hardware Results\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nExact HF energy: {hf_energy_exact:.6f} Ha\\n\")\n",
    "\n",
    "print(f\"Baseline:\")\n",
    "print(f\"  Energy: {baseline_hw_oct.energy:.6f} ± {baseline_hw_oct.energy_std():.6f} Ha\")\n",
    "print(f\"  Error from exact: {abs(baseline_hw_oct.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {baseline_hw_oct.energy_variance:.6e}\")\n",
    "\n",
    "print(f\"\\nPost-hoc Repacking:\")\n",
    "print(f\"  Energy: {posthoc_hw_oct.energy:.6f} ± {posthoc_hw_oct.energy_std():.6f} Ha\")\n",
    "print(f\"  Error from exact: {abs(posthoc_hw_oct.energy - hf_energy_exact):.6f} Ha\")\n",
    "print(f\"  Variance: {posthoc_hw_oct.energy_variance:.6e}\")\n",
    "\n",
    "print(f\"\\nVariance reduction: {variance_reduction_oct:.2f}x ({(1-1/variance_reduction_oct)*100:.1f}% reduction)\")\n",
    "print(f\"Std dev reduction: {std_reduction_oct:.2f}x\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Side-by-side comparison of all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "SUMMARY: All Results\n",
      "====================================================================================================\n",
      "Exact HF Energy: -75.679017 Ha\n",
      "====================================================================================================\n",
      "    Dataset   Method Energy (Ha) Std Dev (Ha) Variance Var. Reduction Circuit Reuse\n",
      " Simulation Baseline  -75.680290     0.004028 1.62e-05          1.00x          100%\n",
      " Simulation   Greedy  -75.679137     0.001768 3.13e-06          5.19x           N/A\n",
      " Simulation Post-hoc  -75.680305     0.001941 3.77e-06          4.31x          100%\n",
      "HW Sep 2025 Baseline  -73.551561     0.006340 4.02e-05          1.00x          100%\n",
      "HW Sep 2025 Post-hoc  -67.995741     0.011542 1.33e-04          0.30x          100%\n",
      "HW Oct 2022 Baseline  -52.837890     0.062171 3.87e-03          1.00x          100%\n",
      "HW Oct 2022 Post-hoc  -49.897433     0.016396 2.69e-04         14.38x          100%\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        'Dataset': 'Simulation',\n",
    "        'Method': 'Baseline',\n",
    "        'Energy (Ha)': f\"{baseline_sim_results.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{baseline_sim_results.energy_std():.6f}\",\n",
    "        'Variance': f\"{baseline_sim_results.energy_variance:.2e}\",\n",
    "        'Var. Reduction': '1.00x',\n",
    "        'Circuit Reuse': '100%'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Simulation',\n",
    "        'Method': 'Greedy',\n",
    "        'Energy (Ha)': f\"{greedy_sim_results.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{greedy_sim_results.energy_std():.6f}\",\n",
    "        'Variance': f\"{greedy_sim_results.energy_variance:.2e}\",\n",
    "        'Var. Reduction': f\"{baseline_sim_results.energy_variance / greedy_sim_results.energy_variance:.2f}x\",\n",
    "        'Circuit Reuse': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Simulation',\n",
    "        'Method': 'Post-hoc',\n",
    "        'Energy (Ha)': f\"{posthoc_sim_results.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{posthoc_sim_results.energy_std():.6f}\",\n",
    "        'Variance': f\"{posthoc_sim_results.energy_variance:.2e}\",\n",
    "        'Var. Reduction': f\"{baseline_sim_results.energy_variance / posthoc_sim_results.energy_variance:.2f}x\",\n",
    "        'Circuit Reuse': '100%'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'HW Sep 2025',\n",
    "        'Method': 'Baseline',\n",
    "        'Energy (Ha)': f\"{baseline_hw_sep.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{baseline_hw_sep.energy_std():.6f}\",\n",
    "        'Variance': f\"{baseline_hw_sep.energy_variance:.2e}\",\n",
    "        'Var. Reduction': '1.00x',\n",
    "        'Circuit Reuse': '100%'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'HW Sep 2025',\n",
    "        'Method': 'Post-hoc',\n",
    "        'Energy (Ha)': f\"{posthoc_hw_sep.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{posthoc_hw_sep.energy_std():.6f}\",\n",
    "        'Variance': f\"{posthoc_hw_sep.energy_variance:.2e}\",\n",
    "        'Var. Reduction': f\"{variance_reduction_sep:.2f}x\",\n",
    "        'Circuit Reuse': '100%'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'HW Oct 2022',\n",
    "        'Method': 'Baseline',\n",
    "        'Energy (Ha)': f\"{baseline_hw_oct.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{baseline_hw_oct.energy_std():.6f}\",\n",
    "        'Variance': f\"{baseline_hw_oct.energy_variance:.2e}\",\n",
    "        'Var. Reduction': '1.00x',\n",
    "        'Circuit Reuse': '100%'\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'HW Oct 2022',\n",
    "        'Method': 'Post-hoc',\n",
    "        'Energy (Ha)': f\"{posthoc_hw_oct.energy:.6f}\",\n",
    "        'Std Dev (Ha)': f\"{posthoc_hw_oct.energy_std():.6f}\",\n",
    "        'Variance': f\"{posthoc_hw_oct.energy_variance:.2e}\",\n",
    "        'Var. Reduction': f\"{variance_reduction_oct:.2f}x\",\n",
    "        'Circuit Reuse': '100%'\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: All Results\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Exact HF Energy: {hf_energy_exact:.6f} Ha\")\n",
    "print(\"=\"*100)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
